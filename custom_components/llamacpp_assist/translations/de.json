{
    "config": {
        "step": {
            "user": {
                "title": "Llama.cpp Assist konfigurieren",
                "description": "Verbinden Sie sich mit Ihrem lokalen llama.cpp Server",
                "data": {
                    "server_url": "Server-URL",
                    "api_key": "API-Schlüssel (optional)",
                    "model_name": "Modellname (optional)",
                    "temperature": "Temperatur",
                    "max_tokens": "Max. Tokens",
                    "timeout": "Zeitüberschreitung (Sekunden)"
                },
                "data_description": {
                    "server_url": "Die URL Ihres llama.cpp Servers (z.B. http://localhost:8080)",
                    "api_key": "Optionaler API-Schlüssel, falls Ihr Server Authentifizierung benötigt",
                    "model_name": "Optionaler Modellname für Anzeigezwecke",
                    "temperature": "Steuert Zufälligkeit (0.0 = deterministisch, 2.0 = sehr kreativ)",
                    "max_tokens": "Maximale Anzahl von Tokens in der Antwort",
                    "timeout": "Zeitüberschreitung der Anfrage in Sekunden"
                }
            }
        },
        "error": {
            "cannot_connect": "Verbindung zum llama.cpp Server fehlgeschlagen. Bitte überprüfen Sie die URL und stellen Sie sicher, dass der Server läuft.",
            "invalid_response": "Der Server hat eine ungültige Antwort zurückgegeben. Bitte stellen Sie sicher, dass es sich um einen kompatiblen llama.cpp Server mit OpenAI API handelt.",
            "timeout": "Zeitüberschreitung der Verbindung. Bitte überprüfen Sie Ihren Server und Ihr Netzwerk.",
            "unknown": "Ein unerwarteter Fehler ist aufgetreten. Bitte überprüfen Sie die Protokolle für Details."
        },
        "abort": {
            "already_configured": "Dieser llama.cpp Server ist bereits konfiguriert."
        }
    },
    "options": {
        "step": {
            "init": {
                "title": "Llama.cpp Assist Konfiguration aktualisieren",
                "data": {
                    "temperature": "Temperatur",
                    "max_tokens": "Max. Tokens",
                    "timeout": "Zeitüberschreitung (Sekunden)",
                    "system_prompt_prefix": "System-Prompt-Präfix",
                    "enable_multi_agentic_system": "Multi-Agenten-System aktivieren",
                    "planner_server_url": "Planner Server-URL (optional)",
                    "selector_server_url": "Selector Server-URL (optional)",
                    "summariser_server_url": "Summariser Server-URL (optional)"
                },
                "data_description": {
                    "temperature": "Steuert Zufälligkeit (0.0 = deterministisch, 2.0 = sehr kreativ)",
                    "max_tokens": "Maximale Anzahl von Tokens in der Antwort",
                    "timeout": "Zeitüberschreitung der Anfrage in Sekunden",
                    "system_prompt_prefix": "Benutzerdefinierter Text, der dem System-Prompt vorangestellt wird",
                    "enable_multi_agentic_system": "Aktiviert das Multi-Agenten-System (Planner, Resolver, Selector, Executor, Summariser)",
                    "planner_server_url": "Separate Server-URL für den Planner-Agent. Leer lassen für Haupt-Server.",
                    "selector_server_url": "Separate Server-URL für den Selector-Agent. Leer lassen für Haupt-Server.",
                    "summariser_server_url": "Separate Server-URL für den Summariser-Agent. Leer lassen für Haupt-Server."
                }
            }
        }
    }
}